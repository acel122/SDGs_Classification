# -*- coding: utf-8 -*-
"""finetune_sdg

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QHeL6U7iJcs57_wCCTZO8yv1DmEHF5ZS

## install
"""

pip install transformers datasets scikit-learn evaluate

"""## import code"""

# import pandas as pd

# df = pd.read_excel("data_noNULL.xlsx")
# print(df)

# df['text'] = df['Title'] + "." + df['Hasil Abstract']

# df.info()

# df.rename(columns={'labels': 'label'}, inplace=True)

# df.to_excel('data_bersih.xlsx', index=False)

# df.head()

!gdown '1CaoeK_kjPSrBTZWz17nEHxfo_rz4AYa5' #ni yg versi label sm text doang

"""## code"""

import pandas as pd
from datasets import Dataset

df = pd.read_excel('data_bersih.xlsx')
df.head()

import ast

df["label"] = df["label"].apply(ast.literal_eval)

sdg_list = [f"SDG {i}" for i in range(1, 18)]
label2id = {sdg: i for i, sdg in enumerate(sdg_list)}
id2label = {i: sdg for sdg, i in label2id.items()}
print(id2label)

import numpy as np

def multilabel_encode(sdg_labels):
    label_vector = np.zeros(len(sdg_list), dtype=float)
    for sdg in sdg_labels:
        if sdg in label2id:
            label_vector[label2id[sdg]] = 1.0
    return label_vector

df["multi_hot_label"] = df["label"].apply(multilabel_encode)
df["labels"] = df["multi_hot_label"].apply(lambda x: x.tolist())

df.head()

print(df["label"].iloc[0])
print(type(df["label"].iloc[0]))

df.to_excel('ada_multihotlabel.xlsx', index=False)

df.head()

dataset_df = df[["text", "labels"]]

dataset_df.head()

from datasets import Dataset

dataset = Dataset.from_pandas(dataset_df)

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("sadickam/sdgBERT")

def tokenize_function(example):
    return tokenizer(example["text"], padding="max_length", truncation=True)

tokenized_dataset = dataset.map(tokenize_function, batched=True)

print(tokenized_dataset)

temp_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)
final_split = temp_split["train"].train_test_split(test_size=0.2, seed=42)

final_dataset = {
    "train": final_split["train"],
    "validation": final_split["test"],
    "test": temp_split["test"]
}

from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(
    "sadickam/sdgBERT",
    num_labels=17,
    problem_type="multi_label_classification",
    ignore_mismatched_sizes=True
)

import numpy as np
from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score

def compute_metrics(pred):
    logits, labels = pred
    probs = 1 / (1 + np.exp(-logits))
    preds = (probs > 0.5).astype(int)
    return {
        "f1_micro": f1_score(labels, preds, average="micro"),
        "precision_micro": precision_score(labels, preds, average="micro"),
        "recall_micro": recall_score(labels, preds, average="micro"),
        "accuracy": accuracy_score(labels, preds)
    }

from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="./sdg_model_output",
    evaluation_strategy="steps",
    eval_steps=100,
    save_strategy="steps",
    save_steps=100,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=10,
    learning_rate=5e-5,
    weight_decay=0.01,
    logging_dir="./logs",
    load_best_model_at_end=True,
    metric_for_best_model="f1_micro",
    fp16=True,
    gradient_accumulation_steps=2
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=final_dataset["train"],
    eval_dataset=final_dataset["validation"],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer.train()
trainer.evaluate(final_dataset["test"])

#@title hyperparameter tuning
from transformers import TrainingArguments
from ray import tune
from ray.tune.schedulers import ASHAScheduler

def hp_space(trial):
    return {
        "learning_rate": tune.loguniform(1e-5, 5e-4),
        "per_device_train_batch_size": tune.choice([8, 16]),
        "num_train_epochs": tune.choice([5, 8, 10, 15]),
        "weight_decay": tune.uniform(0.0, 0.3),
    }

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=final_dataset["train"],
    eval_dataset=final_dataset["validation"],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
    model_init=model_init
)

best_run = trainer.hyperparameter_search(
    hp_space=hp_space,
    direction="maximize",
    backend="ray",
    n_trials=10
)

model_save_path = "/content/drive/MyDrive/magang/satudata/model_2(acc_73%)"
trainer.save_model(model_save_path)
tokenizer.save_pretrained(model_save_path)
print(f"Model saved to {model_save_path}")

#@title Function to predict SDGs for new text input

import torch

def predict_sdgs(text, model, tokenizer, threshold=0.5):
    # Tokenize the input text
    inputs = tokenizer(text, padding="max_length", truncation=True, return_tensors="pt")

    # Move inputs to the same device as the model
    device = model.device
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits

    probs = torch.sigmoid(logits).cpu().numpy()[0]
    predictions = (probs > threshold).astype(int)
    results = []
    for idx, (pred, prob) in enumerate(zip(predictions, probs)):
        if pred == 1:
            sdg_label = id2label[idx]
            results.append((sdg_label, float(prob)))
    results.sort(key=lambda x: x[1], reverse=True)

    return results

def test_with_user_input():
    print("Loading saved model...")
    loaded_model = AutoModelForSequenceClassification.from_pretrained(model_save_path)
    loaded_tokenizer = AutoTokenizer.from_pretrained(model_save_path)

    print("Model loaded successfully!")
    print("\nEnter text to classify (type 'exit' to quit):")

    while True:
        text = input("\nText to analyze: ")
        if text.lower() == 'exit':
            break

        if not text.strip():
            print("Please enter some text to analyze.")
            continue

        results = predict_sdgs(text, loaded_model, loaded_tokenizer)

        if results:
            print("\nPredicted SDGs:")
            for sdg, prob in results:
                print(f"{sdg}: {prob:.4f} ({prob*100:.1f}%)")
        else:
            print("No SDGs matched with confidence above threshold.")

        print("\nEnter new text or type 'exit' to quit")

# Example usage of the testing function
print("\nTesting example text with the model:")
example_text = "Providing clean water and sanitation facilities to rural communities"
example_results = predict_sdgs(example_text, model, tokenizer)
if example_results:
    print(f"Example text: \"{example_text}\"")
    print("Predicted SDGs:")
    for sdg, prob in example_results:
        print(f"{sdg}: {prob:.4f} ({prob*100:.1f}%)")

# Run the interactive testing function
print("\nYou can now test your own inputs:")
test_with_user_input()